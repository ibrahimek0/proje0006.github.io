[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Hakkında",
    "section": "",
    "text": "Merhaba! Ben [İbrahim], veri bilimi, istatistik ve R programlama dili ile ilgileniyorum. Bu siteyi, projelerimi, analizlerimi ve öğrendiklerimi paylaşmak için oluşturdum.\n\n\n\nEğitim: [Karabük] Üniversitesi, [iktisat]\nDeneyim: Veri analizi, görselleştirme, makine öğrenmesi projeleri ve çeşitli analiz çalışmaları\n\n\n\n\nBu sitede şunları bulabilirsiniz: - Veri Analizleri: Farklı veri setleriyle yaptığım analizleri ve elde ettiğim sonuçları paylaşıyorum. - Proje Çalışmaları: Veri bilimi ve makine öğrenmesi üzerine yaptığım projelere buradan ulaşabilirsiniz. - Blog Yazıları: Veri bilimi, R dili ve Quarto hakkında yazılar paylaşıyorum.\n\n\n\nBana ulaşmak isterseniz aşağıdaki kanallardan iletişime geçebilirsiniz:\n\nE-posta: example@example.com\nLinkedIn: LinkedIn Profilin\nGitHub: GitHub Hesabın"
  },
  {
    "objectID": "projects.html#eğitim-ve-deneyim",
    "href": "projects.html#eğitim-ve-deneyim",
    "title": "Hakkında",
    "section": "",
    "text": "Eğitim: [Karabük] Üniversitesi, [iktisat]\nDeneyim: Veri analizi, görselleştirme, makine öğrenmesi projeleri ve çeşitli analiz çalışmaları"
  },
  {
    "objectID": "projects.html#bu-site-hakkında",
    "href": "projects.html#bu-site-hakkında",
    "title": "Hakkında",
    "section": "",
    "text": "Bu sitede şunları bulabilirsiniz: - Veri Analizleri: Farklı veri setleriyle yaptığım analizleri ve elde ettiğim sonuçları paylaşıyorum. - Proje Çalışmaları: Veri bilimi ve makine öğrenmesi üzerine yaptığım projelere buradan ulaşabilirsiniz. - Blog Yazıları: Veri bilimi, R dili ve Quarto hakkında yazılar paylaşıyorum."
  },
  {
    "objectID": "projects.html#iletişim",
    "href": "projects.html#iletişim",
    "title": "Hakkında",
    "section": "",
    "text": "Bana ulaşmak isterseniz aşağıdaki kanallardan iletişime geçebilirsiniz:\n\nE-posta: example@example.com\nLinkedIn: LinkedIn Profilin\nGitHub: GitHub Hesabın"
  },
  {
    "objectID": "odev1.html",
    "href": "odev1.html",
    "title": "Ödev 1: Uzay Gemisi Titanik",
    "section": "",
    "text": "Uzay Gemisi Titanic Projesi\nVeri bilimini korumanın kozmik bir gizemi çözmek için gerekli olduğu 2912 yılında hoş geldiniz. Dört ışık yılı öteden bir iletilen ve işler iyi görünmüyor.\nUzay Gemisi Titanic, bir ay önce fırlatılan bir yıldızlararası yolcu yolculuğuydu. Gemide yaklaşık 13.000 yolcuyla, geminin ilk yolculuğuna çıktı ve göçmenleri güneş sistemimizden yakın yıldızların dönüşünde dönen üç yeni yaşanabilir dış gezegene taşındı.\nİlk varış noktası olan yakıcı 55 Cancri E’ye doğru yolda Alpha Centauri’yi dönerken, dikkatsiz Uzay Gemisi Titanik, bir toz bulutunun içinde saklı bir uzay-zaman anomalisiyle çarpıştı. Ne yazık ki, 1000 yıl önceki ismin babasıyla aynı kaderi paylaştı. Gemi sağlam kalsa da, yolcuların neredeyse ortasında alternatif bir boyuta taşındı.\ntrain.csv Eğitim verisi olarak kullanılacak yolcuların yaklaşık üç ikisine (~8700) ait kişisel kayıtlar. PassengerId Her yolcu için benzersiz bir kimlik. Kimliği, yolcunun seyahat ettiği ve gruptaki numarasını gggg_pp gösteren bir form grubu alır. Bir gruptaki kişiler genellikle aile üyeleridir, ancak her zaman değil. HomePlanet Yolcunun ekonomik gezegeni, genellikle daimi ikamet ettiği gezegen. CryoSleep Yolcunun duraklama süresinin sona erme hareketini almayı seçmeyi seçmediğini belirtir. Kriyo uykudaki yolcu kabinlerine kapatılır. Kabin yolcusunun kabin numarası. Şeklindedirdeck/num/side, Liman veya Sancak için sideolabilir.PS Destinasyon-Yolcunun ineceği gezegen. Yaş Yolcunun yaşı. VIP Yolcunun seyahati sırasında özel VIP hizmeti için ödemelerin yapılmadığı. RoomService , FoodCourt , Alışveriş Merkezi , Spa , VRDeck Uzay Gemisi Titanic’in birçok lüks konaklama için yolcunun ödediği tutar. İsim Yolcunun adı ve soyadı. Taşınan yolcunun başka bir boyuta taşınıp taşınmadığı. Bu hedefi tahmin etmeye çalışmak sütununda yer alır.\n\nlibrary(readr)\ntrain &lt;- read_csv(\"data/train.csv\")\n\nRows: 8693 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PassengerId, HomePlanet, Cabin, Destination, Name\ndbl (6): Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\nlgl (3): CryoSleep, VIP, Transported\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"data/test.csv\")\n\nRows: 4277 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PassengerId, HomePlanet, Cabin, Destination, Name\ndbl (6): Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\nlgl (2): CryoSleep, VIP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlibrary(explore)\n\n\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following object is masked from 'package:explore':\n\n    describe\n\npsych::describe(train)\n\nWarning in FUN(newX[, i], ...): min için eksik olmayan argüman yok; Inf\ndöndürülüyor\nWarning in FUN(newX[, i], ...): min için eksik olmayan argüman yok; Inf\ndöndürülüyor\nWarning in FUN(newX[, i], ...): min için eksik olmayan argüman yok; Inf\ndöndürülüyor\n\n\nWarning in FUN(newX[, i], ...): max için eksik olmayan argüman yok; -Inf\ndöndürülüyor\nWarning in FUN(newX[, i], ...): max için eksik olmayan argüman yok; -Inf\ndöndürülüyor\nWarning in FUN(newX[, i], ...): max için eksik olmayan argüman yok; -Inf\ndöndürülüyor\n\n\n             vars    n    mean      sd median trimmed     mad min   max range\nPassengerId*    1 8693 4347.00 2509.60 4347.0 4347.00 3221.69   1  8693  8692\nHomePlanet*     2 8492    1.67    0.80    1.0    1.58    0.00   1     3     2\nCryoSleep       3 8476     NaN      NA     NA     NaN      NA Inf  -Inf  -Inf\nCabin*          4 8494 3150.79 1975.53 3133.5 3128.98 2670.90   1  6560  6559\nDestination*    5 8511    2.48    0.82    3.0    2.60    0.00   1     3     2\nAge             6 8514   28.83   14.49   27.0   28.28   13.34   0    79    79\nVIP             7 8490     NaN      NA     NA     NaN      NA Inf  -Inf  -Inf\nRoomService     8 8512  224.69  666.72    0.0   64.97    0.00   0 14327 14327\nFoodCourt       9 8510  458.08 1611.49    0.0   88.31    0.00   0 29813 29813\nShoppingMall   10 8485  173.73  604.70    0.0   44.60    0.00   0 23492 23492\nSpa            11 8510  311.14 1136.71    0.0   64.59    0.00   0 22408 22408\nVRDeck         12 8505  304.85 1145.72    0.0   60.20    0.00   0 24133 24133\nName*          13 8493 4234.72 2446.08 4233.0 4234.28 3140.15   1  8473  8472\nTransported    14 8693     NaN      NA     NA     NaN      NA Inf  -Inf  -Inf\n              skew kurtosis    se\nPassengerId*  0.00    -1.20 26.92\nHomePlanet*   0.67    -1.11  0.01\nCryoSleep       NA       NA    NA\nCabin*        0.05    -1.29 21.44\nDestination* -1.10    -0.62  0.01\nAge           0.42     0.10  0.16\nVIP             NA       NA    NA\nRoomService   6.33    65.22  7.23\nFoodCourt     7.10    73.25 17.47\nShoppingMall 12.62   328.60  6.56\nSpa           7.63    81.13 12.32\nVRDeck        7.82    85.94 12.42\nName*         0.00    -1.20 26.54\nTransported     NA       NA    NA\n\n\n\ndescribe_all(test)\n\n# A tibble: 13 × 8\n   variable     type     na na_pct unique   min   mean   max\n   &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 PassengerId  chr       0    0     4277    NA  NA       NA\n 2 HomePlanet   chr      87    2        4    NA  NA       NA\n 3 CryoSleep    lgl      93    2.2      3     0   0.37     1\n 4 Cabin        chr     100    2.3   3266    NA  NA       NA\n 5 Destination  chr      92    2.2      4    NA  NA       NA\n 6 Age          dbl      91    2.1     80     0  28.7     79\n 7 VIP          lgl      93    2.2      3     0   0.02     1\n 8 RoomService  dbl      82    1.9    843     0 219.   11567\n 9 FoodCourt    dbl     106    2.5    903     0 439.   25273\n10 ShoppingMall dbl      98    2.3    716     0 177.    8292\n11 Spa          dbl     101    2.4    834     0 303.   19844\n12 VRDeck       dbl      80    1.9    797     0 311.   22272\n13 Name         chr      94    2.2   4177    NA  NA       NA\n\n\n\n\nVeri Önizleme\nPESSENGER ID Her yolcu için benzersiz bir kimlik. Her kimlik, gggg_pp biçimini alır; burada gggg, yolcunun seyahat ettiği grubu belirtir ve pp, gruptaki numaradır. Bir gruptaki kişiler genellikle aile üyeleridir, ancak her zaman değil.\nOnun yolcusu için benzersiz bir kimlik. Onun kimlik gggg_pp’sini alır; burada gggg, yolcunun birlikte seyahat ettiği grubu belirtir ve pp, grubun içindeki numaradır. Bir gruptaki insanların çoğu aile üyeleridir, ancak her zaman değil.\n\nhead(train$PassengerId)\n\n[1] \"0001_01\" \"0002_01\" \"0003_01\" \"0003_02\" \"0004_01\" \"0005_01\"\n\n\n\nlibrary(stringr)\n\n\ntrain[c(\"ailenum\", \"ailesira\")] &lt;- str_split_fixed(train$PassengerId, \"_\", 2)\n\n\ntest[c(\"ailenum\", \"ailesira\")] &lt;- str_split_fixed(test$PassengerId, \"_\", 2)\n\n\nhead(train[, c(\"PassengerId\",\"ailenum\", \"ailesira\")])\n\n# A tibble: 6 × 3\n  PassengerId ailenum ailesira\n  &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;   \n1 0001_01     0001    01      \n2 0002_01     0002    01      \n3 0003_01     0003    01      \n4 0003_02     0003    02      \n5 0004_01     0004    01      \n6 0005_01     0005    01      \n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ tibble    3.2.1\n✔ ggplot2   3.5.1     ✔ tidyr     1.3.1\n✔ lubridate 1.9.3     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::%+%()   masks psych::%+%()\n✖ ggplot2::alpha() masks psych::alpha()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\ntrain &lt;- train %&gt;%\n  group_by(ailenum) %&gt;%\n  mutate(tek_basina = ifelse(n() == 1, 1, 0)) %&gt;%\n  ungroup()\n\n\ntest &lt;- test %&gt;%\n  group_by(ailenum) %&gt;%\n  mutate(tek_basina = ifelse(n() == 1, 1, 0)) %&gt;%\n  ungroup()\n\n\ntrain &lt;- train %&gt;% select(-ailenum,-ailesira)\ntest &lt;- test %&gt;% select(-ailenum,-ailesira)\n\n\ntrain$tek_basina &lt;- as.factor(train$tek_basina)\ntest$tek_basina &lt;- as.factor(test$tek_basina)\n\n\nsummary(train$tek_basina)\n\n   0    1 \n3888 4805 \n\n\n\n\nCABİN\nYolcunun kaldığı kabin numarası. deck/num/side formunu alır, burada side, P (Sunboard) veya S (Pan) olabilir.\nYolcunun kaldığı kabin numarası. Güverte/numara/yan birleştirilir; burada taraf, İskele için P veya Sancak için S olabilir.\n\nhead(train$Cabin)\n\n[1] \"B/0/P\" \"F/0/S\" \"A/0/S\" \"A/0/S\" \"F/1/S\" \"F/0/P\"\n\n\n\ntrain[c('deck', 'num', 'side')] &lt;- str_split_fixed(train$Cabin, '/', 3)\n\n\ntest[c('deck', 'num', 'side')] &lt;- str_split_fixed(test$Cabin, '/', 3)\n\n\nhead(train[, c(\"Cabin\",\"deck\", \"num\", \"side\")])\n\n# A tibble: 6 × 4\n  Cabin deck  num   side \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 B/0/P B     0     P    \n2 F/0/S F     0     S    \n3 A/0/S A     0     S    \n4 A/0/S A     0     S    \n5 F/1/S F     1     S    \n6 F/0/P F     0     P    \n\n\n\ntrain[train == \"\"] &lt;- NA\ntest[test == \"\"] &lt;- NA\n\n\ntrain &lt;- train %&gt;% select(-Cabin)\ntest &lt;- test %&gt;% select(-Cabin)\n\n\nsummary(as.factor(train$deck))\n\n   A    B    C    D    E    F    G    T NA's \n 256  779  747  478  876 2794 2559    5  199 \n\n\n\ntrain$deck[train$deck %in% c(\"T\", \"NA\")] &lt;- \"Other\"\ntest$deck[test$deck %in% c(\"T\", \"NA\")] &lt;- \"Other\"\ntrain$deck[is.na(train$deck)] &lt;- \"Other\"\ntest$deck[is.na(test$deck)] &lt;- \"Other\"\n\n\nsummary(as.factor(train$deck))\n\n    A     B     C     D     E     F     G Other \n  256   779   747   478   876  2794  2559   204 \n\n\n\ndescribe_all(train)\n\n# A tibble: 17 × 8\n   variable     type     na na_pct unique   min   mean   max\n   &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 PassengerId  chr       0    0     8693    NA  NA       NA\n 2 HomePlanet   chr     201    2.3      4    NA  NA       NA\n 3 CryoSleep    lgl     217    2.5      3     0   0.36     1\n 4 Destination  chr     182    2.1      4    NA  NA       NA\n 5 Age          dbl     179    2.1     81     0  28.8     79\n 6 VIP          lgl     203    2.3      3     0   0.02     1\n 7 RoomService  dbl     181    2.1   1274     0 225.   14327\n 8 FoodCourt    dbl     183    2.1   1508     0 458.   29813\n 9 ShoppingMall dbl     208    2.4   1116     0 174.   23492\n10 Spa          dbl     183    2.1   1328     0 311.   22408\n11 VRDeck       dbl     188    2.2   1307     0 305.   24133\n12 Name         chr     200    2.3   8474    NA  NA       NA\n13 Transported  lgl       0    0        2     0   0.5      1\n14 tek_basina   fct       0    0        2    NA  NA       NA\n15 deck         chr       0    0        8    NA  NA       NA\n16 num          chr     199    2.3   1818    NA  NA       NA\n17 side         chr     199    2.3      3    NA  NA       NA\n\n\n\ntrain &lt;- train %&gt;% select(-Name, -num)\ntest &lt;- test %&gt;% select(-Name, -num)\n\n\ntrain &lt;- train %&gt;%\n  mutate_if(is.logical, as.factor) %&gt;%   # Convert logical columns to factors\n  mutate(across(where(is.character) & !all_of(\"PassengerId\"), as.factor))      # Convert character columns to factors\n\ntest &lt;- test %&gt;%\n  mutate_if(is.logical, as.factor) %&gt;%   # Convert logical columns to factors\n  mutate(across(where(is.character) & !all_of(\"PassengerId\"), as.factor))      # Convert character columns to factors\n\n\nsummary(train)\n\n PassengerId         HomePlanet   CryoSleep           Destination  \n Length:8693        Earth :4602   FALSE:5439   55 Cancri e  :1800  \n Class :character   Europa:2131   TRUE :3037   PSO J318.5-22: 796  \n Mode  :character   Mars  :1759   NA's : 217   TRAPPIST-1e  :5915  \n                    NA's  : 201                NA's         : 182  \n                                                                   \n                                                                   \n                                                                   \n      Age           VIP        RoomService        FoodCourt      \n Min.   : 0.00   FALSE:8291   Min.   :    0.0   Min.   :    0.0  \n 1st Qu.:19.00   TRUE : 199   1st Qu.:    0.0   1st Qu.:    0.0  \n Median :27.00   NA's : 203   Median :    0.0   Median :    0.0  \n Mean   :28.83                Mean   :  224.7   Mean   :  458.1  \n 3rd Qu.:38.00                3rd Qu.:   47.0   3rd Qu.:   76.0  \n Max.   :79.00                Max.   :14327.0   Max.   :29813.0  \n NA's   :179                  NA's   :181       NA's   :183      \n  ShoppingMall          Spa              VRDeck        Transported  tek_basina\n Min.   :    0.0   Min.   :    0.0   Min.   :    0.0   FALSE:4315   0:3888    \n 1st Qu.:    0.0   1st Qu.:    0.0   1st Qu.:    0.0   TRUE :4378   1:4805    \n Median :    0.0   Median :    0.0   Median :    0.0                          \n Mean   :  173.7   Mean   :  311.1   Mean   :  304.9                          \n 3rd Qu.:   27.0   3rd Qu.:   59.0   3rd Qu.:   46.0                          \n Max.   :23492.0   Max.   :22408.0   Max.   :24133.0                          \n NA's   :208       NA's   :183       NA's   :188                              \n      deck        side     \n F      :2794   P   :4206  \n G      :2559   S   :4288  \n E      : 876   NA's: 199  \n B      : 779              \n C      : 747              \n D      : 478              \n (Other): 460              \n\n\n\nsummary(test)\n\n PassengerId         HomePlanet   CryoSleep           Destination  \n Length:4277        Earth :2263   FALSE:2640   55 Cancri e  : 841  \n Class :character   Europa:1002   TRUE :1544   PSO J318.5-22: 388  \n Mode  :character   Mars  : 925   NA's :  93   TRAPPIST-1e  :2956  \n                    NA's  :  87                NA's         :  92  \n                                                                   \n                                                                   \n                                                                   \n      Age           VIP        RoomService        FoodCourt      \n Min.   : 0.00   FALSE:4110   Min.   :    0.0   Min.   :    0.0  \n 1st Qu.:19.00   TRUE :  74   1st Qu.:    0.0   1st Qu.:    0.0  \n Median :26.00   NA's :  93   Median :    0.0   Median :    0.0  \n Mean   :28.66                Mean   :  219.3   Mean   :  439.5  \n 3rd Qu.:37.00                3rd Qu.:   53.0   3rd Qu.:   78.0  \n Max.   :79.00                Max.   :11567.0   Max.   :25273.0  \n NA's   :91                   NA's   :82        NA's   :106      \n  ShoppingMall         Spa              VRDeck        tek_basina      deck     \n Min.   :   0.0   Min.   :    0.0   Min.   :    0.0   0:1937     F      :1445  \n 1st Qu.:   0.0   1st Qu.:    0.0   1st Qu.:    0.0   1:2340     G      :1222  \n Median :   0.0   Median :    0.0   Median :    0.0              E      : 447  \n Mean   : 177.3   Mean   :  303.1   Mean   :  310.7              B      : 362  \n 3rd Qu.:  33.0   3rd Qu.:   50.0   3rd Qu.:   36.0              C      : 355  \n Max.   :8292.0   Max.   :19844.0   Max.   :22272.0              D      : 242  \n NA's   :98       NA's   :101       NA's   :80                   (Other): 204  \n   side     \n P   :2084  \n S   :2093  \n NA's: 100  \n            \n            \n            \n            \n\n\n\n\nAGE\n\nlibrary(ggplot2)\n\n\n# Create a ggplot object for train dataset\np_train &lt;- ggplot(train, aes(x = Age)) +\n  geom_histogram(fill = \"blue\", alpha = 0.5, bins = 20) +\n  labs(title = \"Train Dataset\", x = \"Age\", y = \"Count\") +\n  theme_minimal()\n\n# Create a ggplot object for test dataset\np_test &lt;- ggplot(test, aes(x = Age)) +\n  geom_histogram(fill = \"red\", alpha = 0.5, bins = 20) +\n  labs(title = \"Test Dataset\", x = \"Age\", y = \"Count\") +\n  theme_minimal()\n\n\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\n\ngrid.arrange(p_train, p_test, ncol = 2)\n\nWarning: Removed 179 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 91 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n# Create the histogram for both datasets in one plot without combining\nggplot() +\n  geom_histogram(data = train, aes(x = Age, fill = \"Train\"), \n                 position = \"identity\", alpha = 0.5, bins = 20) +\n  geom_histogram(data = test, aes(x = Age, fill = \"Test\"), \n                 position = \"identity\", alpha = 0.5, bins = 20) +\n  labs(title = \"Histogram of Age Variable\",\n       x = \"Age\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_fill_manual(name = \"Dataset\", values = c(\"Train\" = \"blue\", \"Test\" = \"red\"))\n\nWarning: Removed 179 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 91 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\nHome Planet\n\nsummary(train$HomePlanet)\n\n Earth Europa   Mars   NA's \n  4602   2131   1759    201 \n\n\n\nsummary(test$HomePlanet)\n\n Earth Europa   Mars   NA's \n  2263   1002    925     87 \n\n\n\n# Create a ggplot object for train dataset\np_hptrain &lt;- ggplot(train, aes(x = HomePlanet)) +\n  geom_bar(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Train Dataset\", x = \"Home Planet\", y = \"Count\") +\n  theme_minimal()\n\n# Create a ggplot object for test dataset\np_hptest &lt;- ggplot(test, aes(x = HomePlanet)) +\n  geom_bar(fill = \"red\", alpha = 0.5) +\n  labs(title = \"Test Dataset\", x = \"Home Planet\", y = \"Count\") +\n  theme_minimal()\n\n\ngrid.arrange(p_hptrain, p_hptest, ncol = 2)\n\n\n\n\n\n\n\n\n\n# Create the histogram for both datasets in one plot without combining\nggplot() +\n  geom_bar(data = train, aes(x = HomePlanet, fill = \"Train\"), \n                 position = \"identity\", alpha = 0.5) +\n  geom_bar(data = test, aes(x = HomePlanet, fill = \"Test\"), \n                 position = \"identity\", alpha = 0.5) +\n  labs(title = \"Histogram of Age Variable\",\n       x = \"Home Planet\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_fill_manual(name = \"Dataset\", values = c(\"Train\" = \"blue\", \"Test\" = \"red\"))\n\n\n\n\n\n\n\n\n\n\nTRANSPORTED\n\nggplot(train, aes(x = Transported)) +\n  geom_bar(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Train Dataset\", x = \"Transported\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ ggplot2::%+%()       masks psych::%+%()\n✖ scales::alpha()      masks ggplot2::alpha(), psych::alpha()\n✖ gridExtra::combine() masks dplyr::combine()\n✖ scales::discard()    masks purrr::discard()\n✖ dplyr::filter()      masks stats::filter()\n✖ recipes::fixed()     masks stringr::fixed()\n✖ dplyr::lag()         masks stats::lag()\n✖ yardstick::spec()    masks readr::spec()\n✖ recipes::step()      masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\n\nst_recipe &lt;- recipe(Transported ~ ., data = train) %&gt;% \n  update_role(PassengerId, new_role = \"ID\") %&gt;%\n  step_impute_knn(all_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n\n\n# Specify the logistic regression model\nlogistic_model &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\")\n\n\n# Create a workflow\nst_workflow &lt;- workflow() %&gt;%\n  add_recipe(st_recipe) %&gt;%\n  add_model(logistic_model)\n\n\n# Fit the model directly with the workflow\ntrained_model &lt;- st_workflow %&gt;%\n  fit(data = train)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\n# Prepare the test data and make predictions in one step\npredictions &lt;- trained_model %&gt;%\n  predict(new_data = test) %&gt;%     # Directly pass the test data\n  bind_cols(test)                   # Bind the original test data for reference\n\n\n# Step 3: Extract the id from the test data and the predicted prices\nsubmission &lt;- predictions %&gt;% \n  select(PassengerId = PassengerId, .pred_class = .pred_class) %&gt;%  # Adjust this if the id is stored differently\n  rename(Transported = .pred_class)                # Rename predicted column if needed\n\n\nsubmission &lt;- as.data.frame(submission)\n\n\nsubmission$Transported &lt;- str_to_title(submission$Transported)\n\n\nwrite.csv(submission, \"submission_logistic.csv\", row.names = FALSE, quote = FALSE)\n\n\nrf_model &lt;- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\nset.seed(123)\nrf_wf &lt;-\n  workflow() %&gt;%\n  add_model(rf_model) %&gt;% \n  add_recipe(st_recipe)\nrf_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_knn()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nComputational engine: ranger \n\n\n\nset.seed(123)\nspaceship_val &lt;- validation_split(train, \n                               strata = Transported, \n                               prop = 0.80)\n\nWarning: `validation_split()` was deprecated in rsample 1.2.0.\nℹ Please use `initial_validation_split()` instead.\n\n\n\nrf_results &lt;-\n  rf_wf %&gt;% \n  tune_grid(resamples = spaceship_val,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(accuracy)\n  )\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n\nrf_results %&gt;% \n  collect_predictions()\n\n# A tibble: 43,475 × 7\n   .pred_class id          .row  mtry min_n Transported .config              \n   &lt;fct&gt;       &lt;chr&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;       &lt;chr&gt;                \n 1 FALSE       validation    17    27    12 FALSE       Preprocessor1_Model01\n 2 TRUE        validation    19    27    12 TRUE        Preprocessor1_Model01\n 3 FALSE       validation    28    27    12 FALSE       Preprocessor1_Model01\n 4 FALSE       validation    41    27    12 FALSE       Preprocessor1_Model01\n 5 FALSE       validation    43    27    12 FALSE       Preprocessor1_Model01\n 6 TRUE        validation    52    27    12 TRUE        Preprocessor1_Model01\n 7 TRUE        validation    56    27    12 FALSE       Preprocessor1_Model01\n 8 FALSE       validation    60    27    12 TRUE        Preprocessor1_Model01\n 9 TRUE        validation    71    27    12 TRUE        Preprocessor1_Model01\n10 TRUE        validation    78    27    12 TRUE        Preprocessor1_Model01\n# ℹ 43,465 more rows\n\n\n\nrf_results %&gt;%\n  collect_metrics()\n\n# A tibble: 25 × 8\n    mtry min_n .metric  .estimator  mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1    27    12 accuracy binary     0.788     1      NA Preprocessor1_Model01\n 2    25    16 accuracy binary     0.792     1      NA Preprocessor1_Model02\n 3    25    36 accuracy binary     0.794     1      NA Preprocessor1_Model03\n 4     7    31 accuracy binary     0.804     1      NA Preprocessor1_Model04\n 5    11     4 accuracy binary     0.795     1      NA Preprocessor1_Model05\n 6     3    13 accuracy binary     0.796     1      NA Preprocessor1_Model06\n 7    19    30 accuracy binary     0.791     1      NA Preprocessor1_Model07\n 8    21     8 accuracy binary     0.789     1      NA Preprocessor1_Model08\n 9     9    34 accuracy binary     0.800     1      NA Preprocessor1_Model09\n10    12    22 accuracy binary     0.798     1      NA Preprocessor1_Model10\n# ℹ 15 more rows\n\n\n\nparam_final &lt;- rf_results %&gt;%\n  select_best(metric = \"accuracy\")\nparam_final\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     6     6 Preprocessor1_Model14\n\n\n\nlast_rf_model &lt;- rand_forest(mtry = param_final$mtry, min_n = param_final$min_n, trees = 1000) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\nlast_rf_wf &lt;- rf_wf %&gt;%\n  update_model(last_rf_model)\n\nlast_rf_fit &lt;- \n  last_rf_wf %&gt;% \n  fit(train)\n\n\ntest_pred &lt;- predict(last_rf_fit, test)\n\noptions(warn = getOption(\"warn\"))\ntest_pred_new &lt;- test_pred %&gt;% \n  mutate(.pred_class = str_to_title(.pred_class))\n\n\nsubmission$Transported &lt;- test_pred_new$.pred_class\n\n\nwrite_csv(submission, \"submissionrf.csv\")\n\n\nbt_cls_spec &lt;- \n    boost_tree(trees = 15) %&gt;% \n    # This model can be used for classification or regression, so set mode\n    set_mode(\"classification\") %&gt;% \n    set_engine(\"xgboost\")\n\n\nbt_cls_spec &lt;- \n    boost_tree(trees = 15) %&gt;% \n    # This model can be used for classification or regression, so set mode\n    set_mode(\"classification\") %&gt;% \n    set_engine(\"xgboost\")\n\n\n# Create a workflow\nst_workflow &lt;- workflow() %&gt;%\n  add_recipe(st_recipe) %&gt;%\n  add_model(bt_cls_spec)\n\n\n# Fit the model directly with the workflow\ntrained_model &lt;- st_workflow %&gt;%\n  fit(data = train)\n\n\n# Prepare the test data and make predictions in one step\npredictions &lt;- trained_model %&gt;%\n  predict(new_data = test) %&gt;%     # Directly pass the test data\n  bind_cols(test)                   # Bind the original test data for reference\n\n\n# Step 3: Extract the id from the test data and the predicted prices\nsubmission &lt;- predictions %&gt;% \n  select(PassengerId = PassengerId, .pred_class = .pred_class) %&gt;%  # Adjust this if the id is stored differently\n  rename(Transported = .pred_class)                # Rename predicted column if needed\n\n\nsubmission &lt;- as.data.frame(submission)\n\n\nsubmission$Transported &lt;- str_to_title(submission$Transported)\n\n\nwrite.csv(submission, \"submission_xg.csv\", row.names = FALSE, quote = FALSE)\n\n\nsvm_cls_spec &lt;- \n    svm_poly(cost = 1) %&gt;% \n    # This model can be used for classification or regression, so set mode\n    set_mode(\"classification\") %&gt;% \n    set_engine(\"kernlab\")\n\n\n# Create a workflow\nst_workflow &lt;- workflow() %&gt;%\n  add_recipe(st_recipe) %&gt;%\n  add_model(svm_cls_spec)\n\n\n# Fit the model directly with the workflow\ntrained_model &lt;- st_workflow %&gt;%\n  fit(data = train)\n\n Setting default kernel parameters  \n\n\n\n# Prepare the test data and make predictions in one step\npredictions &lt;- trained_model %&gt;%\n  predict(new_data = test) %&gt;%     # Directly pass the test data\n  bind_cols(test)                   # Bind the original test data for reference\n\n\n# Step 3: Extract the id from the test data and the predicted prices\nsubmission &lt;- predictions %&gt;% \n  select(PassengerId = PassengerId, .pred_class = .pred_class) %&gt;%  # Adjust this if the id is stored differently\n  rename(Transported = .pred_class)                # Rename predicted column if needed\n\n\nsubmission &lt;- as.data.frame(submission)\n\n\nsubmission$Transported &lt;- str_to_title(submission$Transported)\n\n\nwrite.csv(submission, \"submission_polysvm.csv\", row.names = FALSE, quote = FALSE)\n\n\nsvm_cls_spec &lt;- \n  svm_rbf(cost = 1) %&gt;% \n  # This model can be used for classification or regression, so set mode\n  set_mode(\"classification\") %&gt;% \n  set_engine(\"kernlab\")\n\n\n# Create a workflow\nst_workflow &lt;- workflow() %&gt;%\n  add_recipe(st_recipe) %&gt;%\n  add_model(svm_cls_spec)\n\n\n# Fit the model directly with the workflow\ntrained_model &lt;- st_workflow %&gt;%\n  fit(data = train)\n\n\n# Prepare the test data and make predictions in one step\npredictions &lt;- trained_model %&gt;%\n  predict(new_data = test) %&gt;%     # Directly pass the test data\n  bind_cols(test)                   # Bind the original test data for reference\n\n\n# Step 3: Extract the id from the test data and the predicted prices\nsubmission &lt;- predictions %&gt;% \n  select(PassengerId = PassengerId, .pred_class = .pred_class) %&gt;%  # Adjust this if the id is stored differently\n  rename(Transported = .pred_class)                # Rename predicted column if needed\n\n\nsubmission &lt;- as.data.frame(submission)\n\n\nsubmission$Transported &lt;- str_to_title(submission$Transported)\n\n\nwrite.csv(submission, \"submission_rbfsvm.csv\", row.names = FALSE, quote = FALSE)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Hakkında",
    "section": "",
    "text": "Merhaba! Ben [İbrahim], veri bilimi, istatistik ve R programlama dili ile ilgileniyorum. Bu siteyi, projelerimi, analizlerimi ve öğrendiklerimi paylaşmak için oluşturdum.\n\n\n\nEğitim: [Karabük] Üniversitesi, [iktisat]\nDeneyim: Veri analizi, görselleştirme, makine öğrenmesi projeleri ve çeşitli analiz çalışmaları\n\n\n\n\nBu sitede şunları bulabilirsiniz: - Veri Analizleri: Farklı veri setleriyle yaptığım analizleri ve elde ettiğim sonuçları paylaşıyorum. - Proje Çalışmaları: Veri bilimi ve makine öğrenmesi üzerine yaptığım projelere buradan ulaşabilirsiniz. - Blog Yazıları: Veri bilimi, R dili ve Quarto hakkında yazılar paylaşıyorum."
  },
  {
    "objectID": "about.html#eğitim-ve-deneyim",
    "href": "about.html#eğitim-ve-deneyim",
    "title": "Hakkında",
    "section": "",
    "text": "Eğitim: [Karabük] Üniversitesi, [iktisat]\nDeneyim: Veri analizi, görselleştirme, makine öğrenmesi projeleri ve çeşitli analiz çalışmaları"
  },
  {
    "objectID": "about.html#bu-site-hakkında",
    "href": "about.html#bu-site-hakkında",
    "title": "Hakkında",
    "section": "",
    "text": "Bu sitede şunları bulabilirsiniz: - Veri Analizleri: Farklı veri setleriyle yaptığım analizleri ve elde ettiğim sonuçları paylaşıyorum. - Proje Çalışmaları: Veri bilimi ve makine öğrenmesi üzerine yaptığım projelere buradan ulaşabilirsiniz. - Blog Yazıları: Veri bilimi, R dili ve Quarto hakkında yazılar paylaşıyorum."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ana Sayfa",
    "section": "",
    "text": "Merhaba! Bu web sitesi, Uygulamalı Ekonometri dersi için hazırladığım kişisel bir projedir.\nBu sitede, ders kapsamında gerçekleştirdiğim ödevler, projeler ve analizler yer alacak. Ayrıca, econometrics üzerine çeşitli konular hakkında düşüncelerimi ve öğrenim sürecimde karşılaştığım önemli noktaları burada paylaşacağım.\nLütfen üst menüdeki bölümler aracılığıyla siteyi keşfedin. Ödevlerim ve Projelerim sekmesinde detaylı analizlere ulaşabilirsiniz. Ayrıca, hakkımda daha fazla bilgi edinmek için Hakkımda sayfasını ziyaret edebilirsiniz.\n\n\n\nSite içeriği: Uygulamalı ekonometri dersi ödevleri, Verilerle yapılan analizler, R kodları ve sonuçlar, Kişisel düşünceler ve öğrenim notları"
  },
  {
    "objectID": "index.html#projelerim",
    "href": "index.html#projelerim",
    "title": "Ana Sayfa",
    "section": "",
    "text": "Site içeriği: Uygulamalı ekonometri dersi ödevleri, Verilerle yapılan analizler, R kodları ve sonuçlar, Kişisel düşünceler ve öğrenim notları"
  },
  {
    "objectID": "odev2.html",
    "href": "odev2.html",
    "title": "ödev2",
    "section": "",
    "text": "FİNAL\n\n\nAMES\n\n\nGİRİŞ\nBu ödev konut piyasası ile ilgili verilere dayanmaktadır. Keşifsel bir veri analizi ile başlayacağım, ilgilendiğim bazı değişkenleri grafikler üzerinde sunacağım ve dağılımlarını inceleyeceğim. Ödevin ikinci bölümünde, korelasyon ve regresyon analizi yaparak çoklu regresyon modeli oluşturmaya ve modelde mevcut olan sorunları düzeltmeye çalışacağım. Amacım, konut fiyatlarını tahmin etmek için en iyi doğrusal modeli bulmak.\n\nlibrary(AmesHousing)\n\nWarning: package 'AmesHousing' was built under R version 4.4.2\n\n\n\names &lt;- AmesHousing::make_ames()\n\nVeri seti, Ames, Iowa’daki evlerin farklı özelliklerini temsil eden 82 değişkene ait 2930 gözlem içermektedir. Veri dokümantasyonundan, şu değişkenlerin olduğu anlaşılmaktadır: 23 nominal, 23 ordinal, 14 kesikli ve 20 sürekli değişken.\nBu analizi yapmanın en iyi yolu, diğer özelliklere bağlı olması gerektiği için konut fiyatını tahmin edilen değişken olarak kullanmak gibi görünüyor. Benim varsayımım, mahalle, evin büyüklüğü, durumu ve ek özelliklerin nihai fiyatı etkilemesi gerektiği yönünde olacaktır.\nBu nedenle, keşifsel veri analizine ev fiyatlarının dağılımına bakarak başlayacağım.\n\nlibrary(scales)\n\n\nlibrary(ggplot2)\n# Fiyatlarin histogrami\nggplot(ames, aes(x = Sale_Price)) +\n  geom_histogram(color = \"black\", fill = \"lightslateblue\", bins = 50) + \n  scale_x_continuous(labels = comma) +\n  labs(title = \"Ev fiyatlarinin dagilimi\", x = \"FIyat\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAnaliz sürecinde verilerin dağılım şekillerini tanımak önemlidir. Histogramlar, görsel olarak temsil edilen dağılımı görmeye yardımcı olur. Histogramlar, belirli sayıda kutu için veri noktalarının frekanslarını gösterir (Bluman, 2018).\nEv fiyatlarının dağılımı sağa çarpıktır ve çoğu ev 200.000 $’ın altında bir fiyat aralığındadır. Tanımlayıcı istatistiklerden, fiyat aralığının 12789 dolar ile 755000 arasında olduğunu, ortalamanın 180796 ve medyan fiyatın 160.000’e eşit olduğunu biliyorum.\nKeşifsel veri analizinin bir sonraki adımı olarak, evlerin yaşına ve kalitesine bakacağım.\n\nbarplot(table(ames$Year_Built), \n        main = \"Ne zaman En Cok ev kuruldu?\", \n        xlab = \"Yil\",\n        ylab = \"Ev sayilari\")\n\n\n\n\n\n\n\n\nGörünüşe göre 2000’li yılların başında bir konut patlaması yaşanmış ve tam değerleri görmek için frekans tablosuna baktığımda en fazla konutun 2005 yılında (142 konut) inşa edildiğini, bunu 2008 yılında 138 konutun izlediğini ve daha sonra değerin düşmeye başladığını gördüm. 2007 ve 2008 yılları arasında inşa edilen konut sayısı yarı yarıya azalmıştır ve bunun nedeni büyük olasılıkla finansal krizdir.\n\nbarplot(table(ames$Overall_Cond), \n        main = \"Ev ne durumda\", \n        xlab = \"Yil\",\n        ylab = \"Ev sayilari\")\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\names &lt;- ames %&gt;% mutate(Sale_Price = log(Sale_Price))\n\n\nneighbourhoods = tapply(ames$Sale_Price, ames$Neighborhood, median)\nneighbourhoods = sort(neighbourhoods, decreasing = TRUE)\n\ndotchart(neighbourhoods, pch = 21, bg = \"purple1\",\n         cex = 0.85,\n         xlab=\"Evlerin ortalama fiyati\",\n         main = \"Hangi komşu mahallede evler daha pahali?\")\n\nWarning in dotchart(neighbourhoods, pch = 21, bg = \"purple1\", cex = 0.85, : 'x'\nis neither a vector nor a matrix: using as.numeric(x)\n\n\n\n\n\n\n\n\n\nOrtalamayı kullandım çünkü ortalamaya göre aykırı değerlerden daha az etkileniyor (eğer bir milyonun üzerinde bir ev olsaydı, ortalama değer artardı ama orta değer yine aynı kalırdı).\nYukarıdaki grafikten mahallenin ev fiyatlarını etkilediğini görmek mümkün - şehrin en pahalı bölgeleri en ucuz bölgelerinden üç kat daha yüksek fiyatlara sahip\n\n\nANALİZ\nkorelasyon katsayısı iki değişken arasındaki doğrusal ilişkinin gücünü gösterir. Değerleri -1 ile 1 arasında değişir. -1’e yakın bir değere sahip bir katsayı güçlü bir negatif ilişkiyi, 0’a yakın bir katsayı doğrusal ilişkinin olmadığını ve 1’e yakın bir değere sahip bir katsayı güçlü bir pozitif ilişkiyi gösterir .\nBu veri setindeki değişkenler arasındaki korelasyonu görmek istiyorum\n\nlibrary(GGally)\n\nWarning: package 'GGally' was built under R version 4.4.2\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\nnumeric = ames %&gt;% select(where(is.numeric))\ndf1 = numeric %&gt;% select(Sale_Price, Open_Porch_SF, Wood_Deck_SF, Garage_Area, Garage_Cars, Fireplaces, TotRms_AbvGrd, Half_Bath, Full_Bath, Bsmt_Full_Bath, Gr_Liv_Area, Second_Flr_SF, First_Flr_SF, BsmtFin_SF_1, Year_Built, Year_Remod_Add, Lot_Area, Lot_Frontage, Enclosed_Porch)\nggcorr(df1, size = 3)\n\n\n\n\n\n\n\n\nArtık değişkenlerin adlarını görmek daha kolay ve hangilerinin bağımlı değişkenle (Sale Price) en güçlü pozitif ve negatif korelasyona sahip olduğunu belirleyebileceğim.\n\ncor(ames$Sale_Price, ames$Gr_Liv_Area)\n\n[1] 0.6958623\n\n\nevin genel kalitesinin fiyatıyla en yüksek pozitif korelasyona sahip olduğu görülmektedir ki bu da mantıklıdır, çünkü ev ne kadar iyi durumdaysa, alıcılar o kadar fazla ödeme yapmaya isteklidir.\nBununla birlikte, sıralı kategorik bir değişkenle bir dağılım grafiği oluşturmak mantıklı olmayacaktır, bu nedenle satış fiyatı ile feet kare cinsinden yer üstü yaşam alanı arasındaki ilişkiyi çizeceğim.\n\nggplot(ames, aes(Sale_Price, Gr_Liv_Area)) + \n  geom_point(size = 2, color = \"gray35\", alpha = 0.6) + \n  theme_minimal() +\n  geom_smooth(method = lm, color = \"blue\", size = 2) + \n  scale_x_continuous(labels = comma)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDağılım grafikleri, sayısal değişkenlerin sıralı çiftlerini gösterir. Bağımsız ve bağımlı değişkenler arasındaki ilişkiyi (ya da ilişkisizliği) görmeye yardımcı olur. Amaçları, ilgilenilen değişkenler arasındaki ilişkinin doğasını göstermektir.\nŞimdi, fiyat arttığında hem yaşam alanının hem de ev kalitesinin de arttığı açıkça görülebilir. Çizgi, yaşam alanı ile konut fiyatı arasındaki ilişkinin doğrusal bir modelini göstermektedir. Ayrıca veri setinde bazı olağandışı gözlemler olduğu da görülebilir.\nNoktaların ev kalitesine göre renklendirileceği başka bir dağılım grafiği oluşturacağım\n\nplot(ames$Sale_Price, ames$Gr_Liv_Area, \n    pch = 21,  cex=1.2,\n    xlab = \"Fiyat\",\n    ylab = \"Yasam alani\",\n    main = \"Konut fiyatı ve konut kalitesi arasında pozitif doğrusal ilişki\",\n    bg = c(rev(heat.colors(10)))[unclass(ames$Overall_Qual)])\n\n\n\n\n\n\n\n\nSıralı renk ölçeği kullandım, çünkü tüm ayrı kategorileri görmekle o kadar ilgilenmiyorum, bu nedenle renk koyulaştıkça değerler artıyor.\nŞimdi, hangi değişkenin 0,5’e en yakın korelasyon katsayısına sahip olduğunu kontrol edeceğim. Renk aralığında bu değere yakın görünen değişkenleri seçtim ve bazı ayrık veya kategorik değişkenleri eledim.\n\ndf1 = numeric %&gt;% select(Sale_Price, Garage_Area, First_Flr_SF, BsmtFin_SF_1, Mas_Vnr_Area, Lot_Frontage)\n\n\nggcorr(df1, size = 3, label = TRUE, label_size = 4, label_round = 2, label_alpha = TRUE)\n\n\n\n\n\n\n\n\nMetrekare cinsinden yığma kaplama alanını temsil eden değişkenin(Mas_Vn_Area) 0,51 korelasyon katsayısına sahip olduğu görülmektedir.\n\nplot(ames$Sale_Price, ames$Mas_Vnr_Area, \n    pch = 21,  cex=1.2,\n    xlab = \"Fiyat\",\n    ylab = \"Metrekare cinsinden yığma kaplama alanı\",\n    main = \"Fiyat ile Kaplama alani arasindaki iliski\",\n    bg = c(\"red\"))\n\n\n\n\n\n\n\n\n\nlibrary(corrplot)\n\nWarning: package 'corrplot' was built under R version 4.4.2\n\n\ncorrplot 0.95 loaded\n\n\n\ncorr_simple &lt;- function(data = ames,sig = 0.5){\n  \n  df_cor &lt;- ames %&gt;% mutate_if(is.character, as.factor)\n  df_cor &lt;- df_cor %&gt;% mutate_if(is.factor, as.numeric)  \n  corr &lt;- cor(df_cor)\n  #prepare to drop duplicates and correlations of 1     \n  corr[lower.tri(corr,diag = TRUE)] &lt;- NA \n  #drop perfect correlations\n  corr[corr == 1] &lt;- NA   #turn into a 3-column table\n  corr &lt;- as.data.frame(as.table(corr))\n  #remove the NA values from above \n  corr &lt;- na.omit(corr)   #select significant values  \n  corr &lt;- subset(corr, abs(Freq) &gt; sig) \n  #sort by highest correlation\n  corr &lt;- corr[order(-abs(corr$Freq)),]   #print table\n  print(corr)  #turn corr back into matrix in order to plot with corrplot\n  mtx_corr &lt;- reshape2::acast(corr, Var1~Var2, value.var=\"Freq\")\n  #plot correlations visually\n  corrplot(mtx_corr, is.corr = FALSE, tl.col=\"black\", na.label=\" \")\n}\n\ncorr_simple()\n\n               Var1           Var2       Freq\n2706 BsmtFin_Type_1   BsmtFin_SF_1  0.9991444\n4920    Garage_Cars    Garage_Area  0.8898660\n1886   Exterior_1st   Exterior_2nd  0.8654165\n6335   Overall_Qual     Sale_Price  0.8256450\n4339    Gr_Liv_Area  TotRms_AbvGrd  0.8077721\n3440  Total_Bsmt_SF   First_Flr_SF  0.8004287\n1135    MS_SubClass      Bldg_Type  0.7188418\n3499    House_Style  Second_Flr_SF  0.7175417\n2870 BsmtFin_Type_2   BsmtFin_SF_2 -0.7113410\n6364    Gr_Liv_Area     Sale_Price  0.6958623\n6378    Garage_Cars     Sale_Price  0.6748777\n4344  Bedroom_AbvGr  TotRms_AbvGrd  0.6726472\n3689  Second_Flr_SF    Gr_Liv_Area  0.6552512\n4239     Exter_Qual   Kitchen_Qual  0.6535235\n6379    Garage_Area     Sale_Price  0.6507663\n2287     Year_Built     Foundation  0.6366324\n2123   Overall_Qual     Exter_Qual -0.6331484\n3934    Gr_Liv_Area      Full_Bath  0.6303208\n6356  Total_Bsmt_SF     Sale_Price  0.6256220\n2368     Year_Built      Bsmt_Qual -0.6218544\n6337     Year_Built     Sale_Price  0.6154845\n1558     Year_Built Year_Remod_Add  0.6120953\n4013  Second_Flr_SF      Half_Bath  0.6116337\n6361   First_Flr_SF     Sale_Price  0.6026285\n4796   Overall_Qual    Garage_Cars  0.5995467\n1475   Overall_Qual     Year_Built  0.5970272\n4229   Overall_Qual   Kitchen_Qual -0.5896450\n6338 Year_Remod_Add     Sale_Price  0.5861531\n4337  Second_Flr_SF  TotRms_AbvGrd  0.5852137\n3985    House_Style      Half_Bath  0.5850323\n6367      Full_Bath     Sale_Price  0.5773341\n6345     Exter_Qual     Sale_Price -0.5765050\n2366   Overall_Qual      Bsmt_Qual -0.5728611\n6371   Kitchen_Qual     Sale_Price -0.5722473\n3662   Overall_Qual    Gr_Liv_Area  0.5705559\n5740      Pool_Area        Pool_QC -0.5699490\n1556   Overall_Qual Year_Remod_Add  0.5696088\n2376     Exter_Qual      Bsmt_Qual  0.5648838\n4877   Overall_Qual    Garage_Area  0.5635623\n3688   First_Flr_SF    Gr_Liv_Area  0.5621658\n6348      Bsmt_Qual     Sale_Price -0.5509680\n3014   Overall_Qual  Total_Bsmt_SF  0.5477656\n4636     Year_Built    Garage_Type -0.5430286\n5084    Garage_Qual    Garage_Cond  0.5415255\n4232 Year_Remod_Add   Kitchen_Qual -0.5387844\n4798     Year_Built    Garage_Cars  0.5379817\n4342      Full_Bath  TotRms_AbvGrd  0.5285992\n2369 Year_Remod_Add      Bsmt_Qual -0.5276444\n3905   Overall_Qual      Full_Bath  0.5222626\n4096    Gr_Liv_Area  Bedroom_AbvGr  0.5168075\n2378     Foundation      Bsmt_Qual -0.5142868\n6376    Garage_Type     Sale_Price -0.5047736\n4094  Second_Flr_SF  Bedroom_AbvGr  0.5046506\n4242      Bsmt_Qual   Kitchen_Qual  0.5042976\n3179 Year_Remod_Add     Heating_QC -0.5036757\n\n\n\n\n\n\n\n\n\nŞimdi, doğrusal bir model için değişkenleri seçmek daha kolay olmalı. İlgilendiğim değişkenler arasındaki doğrusal ilişkiyi çizerek başlayacağım:\n\ndf2 = ames %&gt;% select(Sale_Price, Garage_Area, First_Flr_SF, Gr_Liv_Area)\n\n# Plot\npairs(df2, \n      main = \"Veri degiskenleri arasindaki iliski\", \n      pch = 21, \n      bg = c(\"royalblue2\"), \n      labels = c(\"Price\",\"Garage Area\",\"1st Floor Area\",\"Living Area\"),\n      lower.panel = NULL, \n      font.labels = 2, \n      cex.labels = 2) \n\n\n\n\n\n\n\n\nÇizimlerden, 1. kat alanı ile yerden yüksek yaşam alanı (evin çok katlı bir planı varsa, birinci ve ikinci kattaki alanların toplamı olduğuna inanıyorum) arasında doğrusal bir ilişki olabileceği görülüyor, bu nedenle çoklu doğrusal bağlantı olup olmadığını kontrol etmem gerekecek.\nBir ilişkinin anlamlılığını test etmek için dağılım grafikleri çizdikten ve korelasyon katsayılarının değerlerini hesapladıktan sonra, bir sonraki adım regresyon doğrusunun denklemini belirlemek olacaktır\n\nlibrary(explore)\n\n\nAttaching package: 'explore'\n\n\nThe following object is masked from 'package:GGally':\n\n    rescale01\n\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\n\n\nset.seed(725)\names_val_split &lt;- initial_validation_split(ames,prop = c(0.7,0.15), strata = Sale_Price)\n\n\names_train &lt;- training(ames_val_split)\names_test &lt;- testing(ames_val_split)\names_validation &lt;- validation(ames_val_split)\n\nStrata olarak Sale_Price değişkeni kullanıldığında, bu değişkenin dağılımı korunarak veri seti oluşturulur. Böylece eğitim ve test setlerinde Sale_Price oranları sabit kalır. Bu yöntem, dengesiz veri setleriyle çalışırken daha doğru sonuçlar elde edilmesine yardımcı olur.\nModel doğrulama (validation), bir modelin gerçek hayatta nasıl performans göstereceğini değerlendirmek için yapılır. Modelin eğitim verileri üzerinde öğrendiklerini, daha önce görmediği yeni veriler üzerinde ne kadar başarılı bir şekilde uygulayabildiği test edilir. Bu süreç, aşırı uyum (overfitting) riskini azaltır ve modelin genel performansını ve genelleme kabiliyetini değerlendirmeyi sağlar.\n\n\nMODEL KURMA\n\n\nLinear Regression\n\nlm_model &lt;- linear_reg() %&gt;% set_engine(\"lm\")\n\n\nbirinci &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built+ Overall_Qual + Garage_Area + First_Flr_SF+ Exter_Qual+ Full_Bath, data=ames_train) %&gt;%\nstep_log(Gr_Liv_Area, base=10)%&gt;%\nstep_dummy(all_nominal_predictors())\n\n\nlm_workflow &lt;- workflow() %&gt;% add_model(lm_model) %&gt;% add_recipe(birinci)\n\n\nlm_fit &lt;- fit(lm_workflow, ames_train)\n\n\names_test_hata &lt;- predict(lm_fit, new_data= ames_test %&gt;% select(-Sale_Price))\n\n\nhead(ames_test_hata)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  11.9\n2  12.3\n3  11.4\n4  11.7\n5  12.0\n6  12.5\n\n\n\names_test_hata &lt;- bind_cols(ames_test_hata, ames_test %&gt;% select(Sale_Price))\n\n\nggplot(ames_test_hata, aes(Sale_Price,  .pred)) + geom_point() + geom_abline(lty = 2) + coord_obs_pred()\n\n\n\n\n\n\n\n\n\names_metrics &lt;- metric_set(rmse,rsq,mae)\n\n\names_metrics(ames_test_hata, truth= Sale_Price, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.174\n2 rsq     standard       0.826\n3 mae     standard       0.120\n\n\n\n\nRANDOM FOREST\n\nrf_model &lt;- rand_forest(trees = 500) %&gt;% \n  set_engine(\"ranger\")%&gt;%\n  set_mode(\"regression\")\n\n\nrf_workflow &lt;- workflow() %&gt;% add_model(rf_model) %&gt;% add_recipe(birinci)\n\n\nrf_fit &lt;- rf_workflow %&gt;% fit(data = ames_train)\n\n\names_test_hata &lt;- predict(rf_fit, new_data= ames_test %&gt;% select(-Sale_Price))\n\n\nhead(ames_test_hata)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  11.9\n2  12.2\n3  11.5\n4  11.6\n5  11.9\n6  12.6\n\n\n\names_test_hata &lt;- bind_cols(ames_test_hata, ames_test %&gt;% select(Sale_Price))\n\n\nhead(ames_test_hata)\n\n# A tibble: 6 × 2\n  .pred Sale_Price\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  11.9       12.1\n2  12.2       12.3\n3  11.5       11.7\n4  11.6       11.6\n5  11.9       11.9\n6  12.6       12.6\n\n\n\nggplot(ames_test_hata, aes(Sale_Price,  .pred)) + geom_point() + geom_abline(lty = 2) + coord_obs_pred()\n\n\n\n\n\n\n\n\n\names_metrics(ames_test_hata, truth= Sale_Price, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.166\n2 rsq     standard       0.845\n3 mae     standard       0.112\n\n\n\n\nSVM\n\nlibrary(parsnip)\n\nsvm_model &lt;- svm_rbf(\n  cost = 1,         # Düzenleme parametresi\n  rbf_sigma = NULL, # RBF kernel parametresi (varsayılan olarak otomatik hesaplanır)\n  margin = 0.1      # Sınıf sınırında esneklik\n) %&gt;%\n  set_engine(\"kernlab\") %&gt;%  # SVM motoru olarak 'kernlab' kullanılıyor\n  set_mode(\"regression\")     # Regresyon modu\n\n\nsvm &lt;- workflow() %&gt;% add_model(svm_model) %&gt;% add_recipe(birinci)\n\n\nsvm_fit &lt;- fit(svm, data = ames_train)\n\n\names_test_hata &lt;- predict(svm_fit, new_data= ames_test %&gt;% select(-Sale_Price))\n\n\nhead(ames_test_hata)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  11.9\n2  12.3\n3  11.4\n4  11.6\n5  12.0\n6  12.5\n\n\n\names_test_hata &lt;- bind_cols(ames_test_hata, ames_test %&gt;% select(Sale_Price))\n\n\nggplot(ames_test_hata, aes(Sale_Price,  .pred)) + geom_point() + geom_abline(lty = 2) + coord_obs_pred()\n\n\n\n\n\n\n\n\n\names_metrics(ames_test_hata, truth= Sale_Price, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.171\n2 rsq     standard       0.837\n3 mae     standard       0.114\n\n\n\n\nARZ VE TALEP FONKSİYONLARI: ÖZET\n\n\nArz Nedir?\nArz, belirli bir dönemde, belirli bir fiyattan üreticilerin piyasaya sunmaya hazır olduğu mal veya hizmet miktarını ifade eder.\nFiyat ile İlişkisi: Üreticiler, fiyatlar yükseldiğinde daha fazla kazanç sağlamak için arz miktarını artırır.\nArz Kanunu: Fiyat yükselirse arz artar, fiyat düşerse arz azalır (diğer tüm faktörler sabit kabul edildiğinde).\n\n\nArz fonksiyonu\nArz fonksiyonu matematiksel olarak şu şekilde ifade edilir: Qs = a + bP\nQₛ: Arz edilen miktar\nP: Fiyat\na: Fiyat sıfır olduğunda arz miktarını gösteren sabit terim (genelde 0 veya negatif bir değerdir).\nb: Fiyat değişimlerinin arz üzerindeki etkisini ölçen katsayı (pozitiftir, çünkü fiyat arttıkça arz artar).\nÖRNEK:\nBir ürünün arz fonksiyonu:\nQs=10+2PQ_s = 10 + 2PQs​=10+2P\nEğer fiyat 5 ise:\nQs=10+2×5=20Q_s = 10 + 2 = 20Qs​=10+2×5=20\nBu durumda üreticiler, fiyat 5 olduğunda 20 birim ürün sunmaya hazırdır.\n\n\nTALEP NEDİR?\nTalep, tüketicilerin belirli bir fiyattan satın almak istedikleri mal veya hizmet miktarını ifade eder.\nFiyat ile İlişkisi: Fiyat düştüğünde talep artar, fiyat yükseldiğinde ise talep azalır. Bu ilişki genellikle ters orantılıdır.\nTALEP FONKSİYONU:\nTalep fonksiyonu matematiksel olarak şu şekilde ifade edilir: Qd = a - bP\nQₐ: Talep edilen miktar\nP: Fiyat\na: Fiyat sıfır olduğunda talep miktarını ifade eden sabit terim.\nb: Fiyat değişimlerinin talep üzerindeki etkisini ölçen katsayı (negatiftir, çünkü fiyat arttıkça talep azalır).\nÖRNEK:\nBir ürünün talep fonksiyonu:\nQd=10−PQ_d = 10 - PQd​=10−P\nEğer fiyat 5 ise:\nQd=10−5=5Q_d = 10 - 5 = 5Qd​=10−5=5\nBu durumda tüketiciler, fiyat 5 olduğunda 5 birim ürün satın almak ister.\n\n\nTALEP ESNEKLİĞİ NEDİR?\nTalep esnekliği, bir malın fiyatındaki değişimlerin talep edilen miktarı nasıl etkilediğini ölçer.\nEsnek Talep: Fiyat değişimlerine karşı talep miktarı belirgin şekilde değişir. Örneğin, lüks ürünler (saat, araba).\nİnelastik Talep: Fiyat değişimlerine karşı talep miktarı çok az değişir veya hiç değişmez. Örneğin, temel ihtiyaç ürünleri (ekmek, su).\nTALEP ESNEKLİĞİ FORMÜLÜ:\nEd = % talep değişimi / % fiyat değişimi\n\n\nARZ ESNEKLİĞİ NEDİR?\nArz esnekliği, bir malın fiyatındaki değişimlerin arz edilen miktarı nasıl etkilediğini ölçer.\nEsnek Arz: Fiyat değişimlerine karşı arz miktarı belirgin şekilde değişir.\nİnelastik Arz: Fiyat değişimlerine karşı arz miktarı çok az değişir veya hiç değişmez.\nARZ ESNEKLİĞİ FORMÜLÜ:\nEs = % arz değişimi / % fiyat değişimi."
  }
]